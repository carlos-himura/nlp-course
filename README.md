Natural Language Processing in Python
This repository contains code and resources for a comprehensive Natural Language Processing (NLP) curriculum, progressing from traditional machine learning techniques to modern Deep Learning and Transformer-based architectures.
Traditional NLP
Focused on interpretability and efficient processing for small-to-medium datasets.
• Sentiment Analysis: Rules-based approaches using VADER.
• Text Classification: Supervised learning using Naïve Bayes and Logistic Regression.
• Topic Modeling: Unsupervised learning using Non-Negative Matrix Factorization (NMF).
Modern NLP (Transformers & LLMs)
Focused on high performance and complex tasks using the Hugging Face Transformers library.
• Encoder-Only Models: Using BERT for Sentiment Analysis and Named Entity Recognition (NER).
• Encoder-Decoder Models: Using BART and T5 for Text Summarization and Zero-Shot Classification.
• Decoder-Only Models: Using GPT for Text Generation.
• Embeddings: Using MiniLM and Cosine Similarity for Document Similarity and recommendation systems
